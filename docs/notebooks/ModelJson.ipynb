{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How to load a model from a json ###\n",
    "This notebook shows how to save the definition into a json object and reload it to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to remove gensim warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib won't work\n"
     ]
    }
   ],
   "source": [
    "from aikit.model_definition import sklearn_model_from_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to be able to define a model by its name and its parameters.\n",
    "The overral syntax is :\n",
    "\n",
    "(<i>ModelName</i> , {<i>hyperparameters</i>})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example : this is a RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RandomForestClassifier', {'n_estimators': 100})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_json = (\"RandomForestClassifier\",{\"n_estimators\":100})\n",
    "rf_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can create using 'sklearn_model_from_param'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn_model_from_param(rf_json)\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is simple : \n",
    "\n",
    "* sklearn model that klass(**kwargs) \n",
    "* corresponds to 2-uple : 'klass',kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can create more complexe model, like GraphPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GraphPipeline',\n",
       " {'models': {'encoder': ('NumericalEncoder',\n",
       "    {'columns_to_use': ['BLOCKNUMBERTOKEN', 'DATETOKEN', 'CURRENCYTOKEN']}),\n",
       "   'vect': ('CountVectorizerWrapper',\n",
       "    {'analyzer': 'char',\n",
       "     'ngram_range': (1, 4),\n",
       "     'columns_to_use': ['STRINGLINE']}),\n",
       "   'rf': ('RandomForestClassifier', {'n_estimators': 500})},\n",
       "  'edges': [('encoder', 'rf'), ('vect', 'rf')]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_enc = (\"NumericalEncoder\",{\"columns_to_use\": [\"BLOCK\" + \"NUMBERTOKEN\",\"DATETOKEN\",\"CURRENCYTOKEN\"]})\n",
    "json_vec = (\"CountVectorizerWrapper\",{\"analyzer\":\"char\",\"ngram_range\":(1,4),\"columns_to_use\":[\"STRINGLINE\"]})\n",
    "json_rf  = (\"RandomForestClassifier\",{\"n_estimators\":500})\n",
    "json_des = (\"GraphPipeline\",{\"models\":{\"encoder\":json_enc,\n",
    "                                       \"vect\":json_vec,\n",
    "                                       \"rf\":json_rf},\n",
    "            \"edges\":[(\"encoder\",\"rf\"),(\"vect\",\"rf\")]})\n",
    "json_des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and again you can convert it to a real model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"160pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 160.30 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 156.296,-112 156.296,4 -4,4\"/>\r\n",
       "<!-- encoder -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>encoder</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"40.2964\" cy=\"-90\" rx=\"40.0939\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"40.2964\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">encoder</text>\r\n",
       "</g>\r\n",
       "<!-- rf -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>rf</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"82.2964\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"82.2964\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">rf</text>\r\n",
       "</g>\r\n",
       "<!-- encoder&#45;&gt;rf -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>encoder&#45;&gt;rf</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.2498,-72.411C55.397,-63.8323 61.782,-53.1908 67.4947,-43.6695\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.5598,-45.3638 72.7036,-34.9881 64.5573,-41.7623 70.5598,-45.3638\"/>\r\n",
       "</g>\r\n",
       "<!-- vect -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>vect</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"125.296\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"125.296\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">vect</text>\r\n",
       "</g>\r\n",
       "<!-- vect&#45;&gt;rf -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>vect&#45;&gt;rf</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.539,-73.1159C110.151,-64.345 103.344,-53.2637 97.295,-43.4162\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.232,-41.51 92.0152,-34.8212 94.2671,-45.174 100.232,-41.51\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x221fb01f0b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpipe = sklearn_model_from_param(json_des)\n",
    "gpipe\n",
    "gpipe.graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericalEncoder(columns_to_use=['BLOCKNUMBERTOKEN', 'DATETOKEN',\n",
       "                                 'CURRENCYTOKEN'],\n",
       "                 desired_output_type='DataFrame', drop_unused_columns=False,\n",
       "                 drop_used_columns=True, encoding_type='dummy',\n",
       "                 max_cum_proba=0.95, max_modalities_number=100,\n",
       "                 max_na_percentage=0.05, min_modalities_number=20,\n",
       "                 min_nb_observations=10, regex_match=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpipe.models[\"encoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpipe.models[\"rf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizerWrapper(analyzer='char', column_prefix='BAG',\n",
       "                       columns_to_use=['STRINGLINE'],\n",
       "                       desired_output_type='SparseArray',\n",
       "                       drop_unused_columns=True, drop_used_columns=True,\n",
       "                       max_df=1.0, max_features=None, min_df=1,\n",
       "                       ngram_range=(1, 4), regex_match=False, tfidf=False,\n",
       "                       vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpipe.models[\"vect\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a model has another has its parameters, like a 'BoxCoxTargetTransformer' or 'Stacker'... it works the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BoxCoxTargetTransformer',\n",
       " {'model': ('GraphPipeline',\n",
       "   {'models': {'encoder': ('NumericalEncoder',\n",
       "      {'columns_to_use': ['BLOCKNUMBERTOKEN', 'DATETOKEN', 'CURRENCYTOKEN']}),\n",
       "     'vect': ('CountVectorizerWrapper',\n",
       "      {'analyzer': 'char',\n",
       "       'ngram_range': (1, 4),\n",
       "       'columns_to_use': ['STRINGLINE']}),\n",
       "     'rf': ('RandomForestClassifier', {'n_estimators': 500})},\n",
       "    'edges': [('encoder', 'rf'), ('vect', 'rf')]}),\n",
       "  'll': 0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_full = \"BoxCoxTargetTransformer\",{\"model\":json_des,\"ll\":0}\n",
    "json_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoxCoxTargetTransformer(ll=0,\n",
       "                        model=GraphPipeline(edges=[('encoder', 'rf'),\n",
       "                                                   ('vect', 'rf')],\n",
       "                                            models={'encoder': NumericalEncoder(columns_to_use=['BLOCKNUMBERTOKEN',\n",
       "                                                                                                'DATETOKEN',\n",
       "                                                                                                'CURRENCYTOKEN'],\n",
       "                                                                                desired_output_type='DataFrame',\n",
       "                                                                                drop_unused_columns=False,\n",
       "                                                                                drop_used_columns=True,\n",
       "                                                                                encoding_type='dummy',\n",
       "                                                                                max_cum_proba=0.95,\n",
       "                                                                                max_modalities_number=100,\n",
       "                                                                                max_na_percenta...\n",
       "                                                                                 random_state=None,\n",
       "                                                                                 verbose=0,\n",
       "                                                                                 warm_start=False),\n",
       "                                                    'vect': CountVectorizerWrapper(analyzer='char',\n",
       "                                                                                   column_prefix='BAG',\n",
       "                                                                                   columns_to_use=['STRINGLINE'],\n",
       "                                                                                   desired_output_type='SparseArray',\n",
       "                                                                                   drop_unused_columns=True,\n",
       "                                                                                   drop_used_columns=True,\n",
       "                                                                                   max_df=1.0,\n",
       "                                                                                   max_features=None,\n",
       "                                                                                   min_df=1,\n",
       "                                                                                   ngram_range=(1,\n",
       "                                                                                                4),\n",
       "                                                                                   regex_match=False,\n",
       "                                                                                   tfidf=False,\n",
       "                                                                                   vocabulary=None)},\n",
       "                                            no_concat_nodes=None,\n",
       "                                            verbose=False))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn_model_from_param(json_full)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"160pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 160.30 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 156.296,-112 156.296,4 -4,4\"/>\r\n",
       "<!-- encoder -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>encoder</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"40.2964\" cy=\"-90\" rx=\"40.0939\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"40.2964\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">encoder</text>\r\n",
       "</g>\r\n",
       "<!-- rf -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>rf</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"82.2964\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"82.2964\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">rf</text>\r\n",
       "</g>\r\n",
       "<!-- encoder&#45;&gt;rf -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>encoder&#45;&gt;rf</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.2498,-72.411C55.397,-63.8323 61.782,-53.1908 67.4947,-43.6695\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.5598,-45.3638 72.7036,-34.9881 64.5573,-41.7623 70.5598,-45.3638\"/>\r\n",
       "</g>\r\n",
       "<!-- vect -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>vect</title>\r\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"125.296\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"125.296\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">vect</text>\r\n",
       "</g>\r\n",
       "<!-- vect&#45;&gt;rf -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>vect&#45;&gt;rf</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.539,-73.1159C110.151,-64.345 103.344,-53.2637 97.295,-43.4162\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.232,-41.51 92.0152,-34.8212 94.2671,-45.174 100.232,-41.51\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x221fb01f400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aikit.model_definition import DICO_NAME_KLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For it to work : the model should be added within <b>DICO_NAME_KLASS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "registered klasses :\n",
       "AgglomerativeClusteringWrapper\n",
       "BoxCoxTargetTransformer\n",
       "CdfScaler\n",
       "Char2VecVectorizer\n",
       "ColumnsSelector\n",
       "CountVectorizerWrapper\n",
       "DBSCANWrapper\n",
       "ExtraTreesClassifier\n",
       "ExtraTreesRegressor\n",
       "FeaturesSelectorClassifier\n",
       "FeaturesSelectorRegressor\n",
       "GraphPipeline\n",
       "KMeansTransformer\n",
       "KMeansWrapper\n",
       "LGBMClassifier\n",
       "LGBMRegressor\n",
       "Lasso\n",
       "LogisticRegression\n",
       "NumImputer\n",
       "NumericalEncoder\n",
       "OutSamplerTransformer\n",
       "PCAWrapper\n",
       "PassThrough\n",
       "Pipeline\n",
       "RandomForestClassifier\n",
       "RandomForestRegressor\n",
       "Ridge\n",
       "StackerClassifier\n",
       "StackerRegressor\n",
       "TargetEncoderClassifier\n",
       "TargetEncoderEntropyClassifier\n",
       "TargetEncoderRegressor\n",
       "TextDefaultProcessing\n",
       "TextDigitAnonymizer\n",
       "TextNltkProcessing\n",
       "TruncatedSVDWrapper\n",
       "Word2VecVectorizer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICO_NAME_KLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For it to work, each model should be registered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
